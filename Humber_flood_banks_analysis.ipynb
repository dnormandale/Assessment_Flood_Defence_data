{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5457c937",
   "metadata": {},
   "source": [
    "# Humber flood embankment analysis\n",
    "\n",
    "A suite of shapefile data for understanding spatial distribution of available LIDAR and Geophysical survey-derived geotechnical data for engineered flood defence embankments on the Humber estuary, England."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19920e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# this is a line-orientated function which will ensure that \n",
    "# any produced figures (such as a map in this case) are within the notebook.\n",
    "# for more info see: https://stackoverflow.com/questions/43027980/purpose-of-matplotlib-inline\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy.feature import ShapelyFeature\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "# these are modules that require importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed7213",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion() # in this interactive mode, the map will be shown immediately and shown after every redraw;\n",
    "# for more info see:\n",
    "# https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.isinteractive.html#matplotlib.pyplot.isinteractive\n",
    "\n",
    "# generates a legend to be populated by the datesets later;\n",
    "# for more info see https://matplotlib.org/stable/tutorials/intermediate/legend_guide.html\n",
    "def generate_handles(labels, colors, edge='k', alpha=1):\n",
    "    lc = len(colors)  \n",
    "    handles = []\n",
    "    for i in range(len(labels)):\n",
    "        handles.append(mpatches.Rectangle((0, 0), 1, 1, facecolor=colors[i % lc], edgecolor=edge, alpha=alpha))\n",
    "    return handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f96a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the scale bar in preparation for finalised map, based on scale of Humber estuary, 20km fits best\n",
    "# for for info see https://stackoverflow.com/q/32333870 and also https://stackoverflow.com/a/35705477\n",
    "def scale_bar(ax, location=(0.92, 0.95)):\n",
    "    x0, x1, y0, y1 = ax.get_extent()\n",
    "    sbx = x0 + (x1 - x0) * location[0]\n",
    "    sby = y0 + (y1 - y0) * location[1]\n",
    "\n",
    "    ax.plot([sbx, sbx - 20000], [sby, sby], color='k', linewidth=9, transform=ax.projection)\n",
    "    ax.plot([sbx, sbx - 10000], [sby, sby], color='k', linewidth=6, transform=ax.projection)\n",
    "    ax.plot([sbx-10000, sbx - 20000], [sby, sby], color='w', linewidth=6, transform=ax.projection)\n",
    "\n",
    "    ax.text(sbx, sby-4500, '20 km', transform=ax.projection, fontsize=10)\n",
    "    ax.text(sbx-12500, sby-4500, '10 km', transform=ax.projection, fontsize=10)\n",
    "    ax.text(sbx-24500, sby-4500, '0 km', transform=ax.projection, fontsize=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207207d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open Flood Areas polygon shapefile as this will be the basemap for subsequent data;\n",
    "# note that this and subsequent shapefiles are loaded using Geopandas, which associates each with a GeoDataFrame;\n",
    "# GeoDataFrame - tabular data structure, adds 'geometry' column to the shaoefile attribute table.\n",
    "areas = gpd.read_file('HSCR_Flood_Areas/HSCR_FloodAreas_2080406.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see a subset of the first 5 lines, the key column is FloodArea_ and basemap will be rendered on this basis;\n",
    "# note the additional 'geometry' column, as this is a GeoDataFrame.\n",
    "areas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open flood embankment network polylines shapefile; contains all the earth flood defence embankments around the Humber\n",
    "defences = gpd.read_file('Flood_embankment_network/Embankment_alignment_Humber_primary.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24057789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open low sections polyline shapefile; contains LIDAR-derived data of where flood embankments are lower in height\n",
    "# than adjacent sections and could present a flood risk from overtopping during storm events when water levels are high\n",
    "Low_sections = gpd.read_file('LIDAR_derived_data/Embankment_low_sections_defects.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open steep slopes polygon shapefile; contains LIDAR-derived data of where flood embankments slopes, either front (facing the water) or rear (facing the land),\n",
    "# are steeper than the standard angle of repose and could theoretically affect the long-term stability of the embankments\n",
    "Steep_slopes = gpd.read_file('LIDAR_derived_data/Embankment_steep_slope_anomalies.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e065cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open palaeochannels point data shapefile; contains LIDAR-derived data of where infilled former channels, either natural \n",
    "# or engineered are situated directly below earth embankments and may theoretically affect the structural stability\n",
    "Palaeochannels = gpd.read_file('LIDAR_derived_data/Palaeochannel_anomalies_intersect_embank.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8565853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open geophysical survey polyline shapefile; contains interpreted data from DEMP (Dipole Electromagnetic Profiling)\n",
    "# as to the material composition of surveyed flood embankments, which provide geotechnical context to assessments\n",
    "Geophysical_survey_bank_materials = gpd.read_file('Geophysical_survey_data_material_composition/Geophysical_survey_embankment_materials.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd169dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the key datasets are opened, comparative analysis can be started; first on the defence, see subset of columns, rows\n",
    "#in the GeoDataFrame.\n",
    "defences.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdbd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to establish the linear length of earth embankment flood defences on the Humber estuary and main tidal tributary\n",
    "# rivers, the 'Shape_Leng' column is totalled up in metres and converted to kilometres (divide by 1000).\n",
    "defences['Shape_Leng'].sum()/1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59859221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next dataset to be compared is the low sections; see subset of the data and note again a 'Shape_Leng' column\n",
    "Low_sections.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b974d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum and convert to km\n",
    "Low_sections['Shape_Leng'].sum()/1000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find low sections linear length as a percentage of defences to understand the scale of this type of this issue.\n",
    "# output should be 1.5% rounded up, so an issue which only affects a tiny proportion of the embankments.\n",
    "Low_sections['Shape_Leng'].sum()/defences['Shape_Leng'].sum()*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba03bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steep slopes is a polygonal dataset; in this instance Shape_Leng refers to the perimeter of each polygon in the dataset,\n",
    "# rather than the linear length of embankment which is affected; Shape_Area does not relate to linear length either.\n",
    "Steep_slopes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546e7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative analysis can be carried out on how many of these occurrences are present.\n",
    "Steep_slopes['Face'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f40ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are over 4000 instances, more context can be derived from understanding which face (slope) of the embankments\n",
    "# are affected, the subset of the GeoDataframe above just indicated 'front' but a check can be carried out to\n",
    "# establish whether rear slopes are also listed.\n",
    "type_Steep_slopes = list(Steep_slopes.Face.unique())\n",
    "print('Name of unique features: {}'.format(type_Steep_slopes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many of the 4029 are affecting the front slope/face\n",
    "Steep_slopes[Steep_slopes['Face'] == 'Front'].count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many are affecting the rear slope/face\n",
    "Steep_slopes[Steep_slopes['Face'] == 'Rear'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe5e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the instances of rear slope/face as a percentage of the total instance and by deduction,\n",
    "# the remaining percentage of front slope: 74.3 % rear (to 1 d.p) and 25.7 % front.\n",
    "2995/4029*100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See a subset of the Palaeochannels point data; the key column for further analysis is 'Class'.\n",
    "Palaeochannels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be0fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the data are points, linear length calculation is not applicable; instead calculate instances.\n",
    "Palaeochannels['Class'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c75d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 53 palaeochannels are identified in the data; define how many descriptive types there are.\n",
    "num_Palaeochannels = len(Palaeochannels.channel.unique())\n",
    "print('Number of unique features: {}'.format(num_Palaeochannels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the names of these 2 unique features.\n",
    "type_Palaeochannels = list(Palaeochannels.channel.unique())\n",
    "print('Name of unique features: {}'.format(type_Palaeochannels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many of the overall 53 are classed as 'depression'\n",
    "# 'depression' means a palaeochannel is lower in elevation than the surrounding land, as identified in LIDAR analysis. \n",
    "Palaeochannels.loc[Palaeochannels['channel'] == 'Depression'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 49 depressions as a % of total 53 palaeochannels; answer is 92.5% (1 d.p), therefore 'extrusions'\n",
    "# where a palaeochannel is higher in elevation than the surrounding land constitute 7.5% of the total.\n",
    "49/53*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data to analyse are the geophysical survey results; note there are a significant number of columns (27).\n",
    "Geophysical_survey_bank_materials.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb292d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the column headings to aid appreciation of what data are included.\n",
    "Geophysical_survey_bank_materials.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now establish the number of features i.e. the rows.\n",
    "rows, cols = Geophysical_survey_bank_materials.shape \n",
    "print('Number of features: {}'.format(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e51137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the linear distance of survey conducted, using 'Tot_dist_m' which accurately reflects the actual length of \n",
    "# survey undertaken, rather than 'Shape_leng', which is a measure of the polyline lengths. Convert to km. \n",
    "Geophysical_survey_bank_materials['Tot_dist_m'].sum()/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390a2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As these data are linear, a percentage calculation can be made in respect to the overall lemgth of earth embankments;\n",
    "# 37.2 % (to 1 d.p) has been surveyed, leaving 62.3 % available for future survey.\n",
    "Geophysical_survey_bank_materials['Tot_dist_m'].sum()/defences['Shape_Leng'].sum()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The geophysical results have been interpreted in respect of the types of material within the embankments;\n",
    "# Create a list of all these material types;\n",
    "# Material types are based on four standard material types - clay, silt, sand, gravel. Where any of these materials\n",
    "# are considered the dominant constiuents, the name is shown in upper case, with lesser constituents in lower case.\n",
    "type_materials = list(Geophysical_survey_bank_materials.Material.unique())\n",
    "print('Name of unique features: {}'.format(type_materials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ce54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flood embankments should optimally be constructed from finer-grained, cohesive materials - clays and silts;\n",
    "# Where coarser-grained, less cohesive (and therefore more permeable) materials predominate there is theoretically\n",
    "# a greater risk of seepage of water through an embankment body and possibly also increased settlement of the crest\n",
    "# height as there are moe micro voids in coarser-grained materials;\n",
    "# This analysis, by linear length of material types will give a valuable overview.\n",
    "Geophysical_survey_bank_materials.groupby(['Material'])['Tot_dist_m'].sum()/1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inherent saturation levels of the flood embankments is also a key factor in understanding embankment effectivness;\n",
    "# 'High' saturation indicates waterlogging,which is sub-optimal, as is 'Low' , which indicates excessive permeability;\n",
    "# By definition 'Normal' is optimal and from this analysis is the dominant Saturation type - 85 of 125 km.\n",
    "Geophysical_survey_bank_materials.groupby(['Saturation'])['Tot_dist_m'].sum()/1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f32747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand the spatial coverage of geophysical survey, data can be grouped by Hydraulic Units, into which the \n",
    "# Humber estuary interest area is sub-divided based on it's hydraulic functioning in times of flood.\n",
    "# Calculate and convert to km.\n",
    "Geophysical_survey_bank_materials.groupby(['HS_Hyd_Uni'])['Tot_dist_m'].sum()/1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295c915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of Hydraulic Units in which geophysical survey was carried out.\n",
    "num_Units_surveyed = len(Geophysical_survey_bank_materials.HS_Hyd_Uni.unique())\n",
    "print('Number of unique features: {}'.format(num_Units_surveyed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ce1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full list of Hydraulic Units on the Humber, based on the Areas GeoDataFrame.\n",
    "full_list_Units = list(areas.UNIT.unique())\n",
    "print('Name of unique features: {}'.format(full_list_Units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a56188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of Hydraulic Units\n",
    "# There are 15, therefore geophysical survey has been carried out in 10 of 15.\n",
    "num_Units = len(areas.UNIT.unique())\n",
    "print('Number of unique features: {}'.format(num_Units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca9ae4a",
   "metadata": {},
   "source": [
    "# Create map displaying above data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f35da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myFig = plt.figure(figsize=(16, 16))  # creates figure with definied dimensions in inches\n",
    "\n",
    "myCRS = ccrs.OSGB()  # Set the CartoPy Coordinate reference system to the Ordnance Survey Great Britain to ensure \n",
    "# compatibility with all the datasets.\n",
    "\n",
    "ax = plt.axes(projection=myCRS) # create axes using the OSGB projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the Areas basemap, edged in light grey and with a white face colour.\n",
    "areas_feature = ShapelyFeature(areas['geometry'], myCRS, edgecolor='lightgray', facecolor='w')\n",
    "xmin, ymin, xmax, ymax = areas.total_bounds\n",
    "# Add this feature to the map\n",
    "ax.add_feature(areas_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a774ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the zoom extent to match the basemap shapefile extent with a 10km buffer on the x and y axes\n",
    "ax.set_extent([xmin-10000, xmax+10000, ymin-10000, ymax+10000], crs=myCRS)\n",
    "\n",
    "\n",
    "myFig # draw the updated map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f53457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To colour in the Areas basemap, the number of colours required will be the total Flood Area features.\n",
    "num_areas = len(areas.FloodArea_.unique())\n",
    "print('Number of unique features: {}'.format(num_areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14292780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose 35 colours from here https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "areas_colors = ['sandybrown', 'bisque', 'tan', 'moccasin', 'floralwhite', 'gold', 'darkkhaki', 'lightgoldenrodyellow', 'olivedrab', 'chartreuse', 'palegreen', 'mediumspringgreen', 'lightseagreen', 'paleturquoise', 'darkturquoise', 'deepskyblue', 'mediumpurple', 'darkorchid', 'plum', 'm', 'palevioletred', 'lightgray', 'lightcoral', 'mistyrose', 'peachpuff', 'navajowhite', 'orange', 'lemonchiffon', 'yellowgreen', 'c', 'skyblue', 'violet', 'fuchsia', 'indianred', 'salmon', 'y' ]\n",
    "\n",
    "# list and sort the areas\n",
    "area_numbers = list(areas.FloodArea_.unique())\n",
    "area_numbers.sort()  \n",
    "\n",
    "# set more parameters as arguments, including the geometry (from the GeoDataFrame), edge colour, line width \n",
    "# and transparency (alpha - on a scale 0 to 1); face colour is set to the listed colours above.\n",
    "for ii, name in enumerate(area_numbers):\n",
    "    feat = ShapelyFeature(areas.loc[areas['FloodArea_'] == name, 'geometry'],\n",
    "                          myCRS,\n",
    "                          edgecolor='w', \n",
    "                          facecolor=areas_colors[ii], \n",
    "                          linewidth=0.1, \n",
    "                          alpha=0.25) \n",
    "    ax.add_feature(feat) # add features to map\n",
    "\n",
    "myFig # draw updated map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430dd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add defences in the same way\n",
    "defences = ShapelyFeature(defences['geometry'],\n",
    "                            myCRS, \n",
    "                            edgecolor='b', # blue\n",
    "                            linewidth=2.0,\n",
    "                          alpha=0.25\n",
    "                         ) \n",
    "ax.add_feature(defences) # add features to the map\n",
    "\n",
    "myFig # draw updated map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add geophysical survey data\n",
    "Geophysical_survey_bank_materials = ShapelyFeature(Geophysical_survey_bank_materials['geometry'], \n",
    "                            myCRS, \n",
    "                            edgecolor='lime', \n",
    "                            linewidth=1.0,\n",
    "                            )                  \n",
    "ax.add_feature(Geophysical_survey_bank_materials) \n",
    "\n",
    "myFig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7555734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add low sections data\n",
    "Low_sections = ShapelyFeature(Low_sections['geometry'], \n",
    "                            myCRS, \n",
    "                            edgecolor='darkorange', \n",
    "                            linewidth=1.0) \n",
    "ax.add_feature(Low_sections) \n",
    "\n",
    "myFig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76356c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add Steep slopes, note as these data are polygons, the facecolor needs to be set\n",
    "Steep_slopes = ShapelyFeature(Steep_slopes['geometry'], \n",
    "                            myCRS, \n",
    "                            edgecolor='k', # black\n",
    "                            facecolor='k', # due to scale of map, a separate colour will not be discernible\n",
    "                            linewidth=0.1) \n",
    "ax.add_feature(Steep_slopes) \n",
    "\n",
    "myFig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a4767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Palaeochannels are point data so do not need the ShapelyFeature class from cartopy.feature, ax.plot can be used directly.\n",
    "\n",
    "Palaeochannels_handle = ax.plot(Palaeochannels.geometry.x, Palaeochannels.geometry.y, 'o', color='0.7', ms=3, transform=myCRS)\n",
    "# 'o' is circle, courtesy of list here https://stackoverflow.com/questions/8409095/set-markers-for-individual-points-on-a-line\n",
    "# colour is String representation of float value in closed interval [0, 1] for grayscale values, os 0.7 is light grey\n",
    "# see https://matplotlib.org/stable/tutorials/colors/colors.html\n",
    "\n",
    "myFig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use generate-handles function to add labels and colours. Note - Areas is omitted for visual clarity, given there\n",
    "# are 35 areas.\n",
    "\n",
    "defences_handle = generate_handles(['Flood embankments'], ['b'], alpha=0.25)\n",
    "\n",
    "Low_sections_handle = generate_handles(['Low sections of embankments'], ['darkorange'])\n",
    "\n",
    "Steep_slopes_handle = generate_handles(['Steep embankment slopes'], ['k'])\n",
    "\n",
    "Palaeochannels_handle = generate_handles(['Palaeochannel intersections'], ['chocolate'])\n",
    "\n",
    "Geophysical_survey_bank_materials_handle = generate_handles(['Geophysical survey extents'], ['lime'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce94c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate legend content and parameters\n",
    "# for more info see https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html\n",
    "\n",
    "handles = defences_handle + Low_sections_handle + Steep_slopes_handle + Palaeochannels_handle + Geophysical_survey_bank_materials_handle # use '+' to concatenate (combine) lists\n",
    "labels = ['Flood embankments', 'Low sections of embankments', 'Steep embankment slopes', 'Palaeochannel intersections', 'Geophysical survey extents']\n",
    "\n",
    "leg = ax.legend(handles, labels, title='Legend', title_fontsize=14,\n",
    "                 fontsize=12, loc='upper left', frameon=True, framealpha=1)\n",
    "\n",
    "myFig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486811c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now add scale bar which was previously specified\n",
    "scale_bar(ax)\n",
    "\n",
    "myFig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1247e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the map to the current folder in png format; also specify no border (bbox) and resolution in dpi (dots per inch).\n",
    "myFig.savefig('Humber_flood_embankment_data.png', bbox_inches='tight', dpi=800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
